# ğŸš€ LangChainæ¶æ„è¿ç§»æŒ‡å—

## ğŸ“‹ è¿ç§»æ¦‚è¿°

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨ä»åŸå§‹æ¶æ„è¿ç§»åˆ°Based on LangChainçš„ç°ä»£åŒ–æ¶æ„ï¼Œè·å¾—æ›´å¼ºå¤§çš„åŠŸèƒ½å’Œæ›´å¥½çš„å¯ç»´æŠ¤æ€§ã€‚

## ğŸ—ï¸ æ¶æ„å¯¹æ¯”

### åŸå§‹æ¶æ„ vs LangChainæ¶æ„

| ç»„ä»¶ | åŸå§‹æ¶æ„ | LangChainæ¶æ„ | ä¼˜åŠ¿ |
|------|----------|---------------|------|
| **RAGSystem** | è‡ªå®šä¹‰å®ç° | LangChain Chains | æ ‡å‡†åŒ–ã€å¯æ‰©å±• |
| **æ–‡æ¡£Processing** | åŸºç¡€æ–‡æœ¬åˆ†å‰² | å¤šç§Loadingå™¨ + æ™ºèƒ½åˆ†å‰² | æ”¯æŒæ›´å¤šæ ¼å¼ |
| **Memory management** | ç®€å•åˆ—è¡¨ | ConversationBufferWindowMemory | ä¸“ä¸šMemory management |
| **å·¥å…·é›†æˆ** | æ—  | LangChain Tools | ä¸°å¯Œçš„å·¥å…·ç”Ÿæ€ |
| **é“¾å¼ç»„åˆ** | æ‰‹åŠ¨ç»„åˆ | LangChain Chains | çµæ´»çš„ç»„åˆæ–¹å¼ |
| **ä»£ç†System** | æ—  | LangChain Agents | æ™ºèƒ½å†³ç­–èƒ½åŠ› |

## ğŸ”„ è¿ç§»æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…æ–°ä¾èµ–

```bash
# å®‰è£…LangChainç›¸å…³ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python -c "import langchain; print('LangChainå®‰è£…Success')"
```

### ç¬¬äºŒæ­¥ï¼šç¯å¢ƒConfiguration

```bash
# å¤åˆ¶ç¯å¢ƒå˜é‡File
cp env.example .env

# ç¼–è¾‘.envFileï¼Œç¡®ä¿åŒ…å«ï¼š
GROQ_API_KEY=your_groq_api_key_here
VECTOR_DB_PATH=./data/vector_db
```

### ç¬¬ä¸‰æ­¥ï¼šInitializeLangChainSystem

```bash
# è¿è¡ŒLangChainInitializeScript
python langchain_run.py
```

### ç¬¬å››æ­¥ï¼šStart service

```bash
# å¯åŠ¨LangChain Webç•Œé¢
streamlit run langchain_app.py

# æˆ–å¯åŠ¨LangChain APIService
uvicorn api.langchain_api:app --reload
```

### ç¬¬äº”æ­¥ï¼šè¿è¡Œæµ‹è¯•

```bash
# è¿è¡ŒLangChainæµ‹è¯•
python test_langchain.py
```

## ğŸ†• æ–°åŠŸèƒ½ç‰¹æ€§

### 1. å¤šç§èŠå¤©æ¨¡å¼

```python
# åŸºç¡€å¯¹è¯
result = await chat_manager.chat("ä½ å¥½", chat_type="basic")

# RAGå¢å¼ºå¯¹è¯
result = await chat_manager.chat("ä»€ä¹ˆæ˜¯RAGï¼Ÿ", chat_type="rag")

# é—®é¢˜åˆ†æ
result = await chat_manager.chat("å¦‚ä½•ä¼˜åŒ–æ€§èƒ½ï¼Ÿ", chat_type="analysis")

# åˆ›æ„å†…å®¹
result = await chat_manager.chat("AIçš„æœªæ¥", chat_type="creative")
```

### 2. æ™ºèƒ½æ–‡æ¡£Processing

```python
# æ”¯æŒå¤šç§æ ¼å¼
documents = document_processor.load_document("file.pdf")
documents = document_processor.load_directory("./docs/")
documents = document_processor.load_web_content(["https://example.com"])

# æ™ºèƒ½åˆ†å‰²å’ŒProcessing
split_docs = document_processor.split_documents(documents)
processed_docs = document_processor.process_documents(split_docs)
```

### 3. é«˜çº§Memory management

```python
# å¯¹è¯çª—å£å†…å­˜
memory = ConversationBufferWindowMemory(k=10)

# æ‘˜è¦å†…å­˜ï¼ˆé•¿å¯¹è¯ï¼‰
summary_memory = ConversationSummaryMemory(llm=llm)

# å†…å­˜æ“ä½œ
memory.clear()
memory_info = memory.get_memory_summary()
```

### 4. å·¥å…·é›†æˆ

```python
# å†…ç½®å·¥å…·
tools = [
    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper()),
    vector_search_tool,
    document_summary_tool
]

# ä»£ç†Useå·¥å…·
agent = initialize_agent(tools, llm, agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION)
```

## ğŸ”§ Configurationé€‰é¡¹

### LangChainConfiguration

```python
# åœ¨ core/langchain_config.py ä¸­Configuration
class LangChainConfig:
    def __init__(self):
        # LLMConfiguration
        self.llm = Groq(
            groq_api_key=settings.groq_api_key,
            model_name="llama3-8b-8192",
            temperature=0.7
        )
        
        # åµŒå…¥ModelConfiguration
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # æ–‡æœ¬åˆ†å‰²Configuration
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
```

### å†…å­˜Configuration

```python
# å¯¹è¯çª—å£å†…å­˜
memory = ConversationBufferWindowMemory(
    k=10,  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
    memory_key="chat_history",
    return_messages=True
)

# æ‘˜è¦å†…å­˜
summary_memory = ConversationSummaryMemory(
    llm=llm,
    memory_key="chat_history",
    return_messages=True
)
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. Vector storageä¼˜åŒ–

```python
# UseFAISSæé«˜æœç´¢æ€§èƒ½
from langchain.vectorstores import FAISS

vectorstore = FAISS.from_documents(documents, embeddings)
```

### 2. é“¾å¼ä¼˜åŒ–

```python
# UseMapReduceé“¾Processingé•¿æ–‡æ¡£
from langchain.chains import MapReduceDocumentsChain

map_reduce_chain = MapReduceDocumentsChain.from_llm(llm)
```

### 3. ç¼“å­˜ä¼˜åŒ–

```python
# å¯ç”¨LLMç¼“å­˜
from langchain.cache import InMemoryCache
from langchain.globals import set_llm_cache

set_llm_cache(InMemoryCache())
```

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### è¿è¡Œæµ‹è¯•å¥—ä»¶

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python test_langchain.py

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -c "
import asyncio
from test_langchain import test_llm
asyncio.run(test_llm())
"
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•

```python
# æµ‹è¯•å“åº”æ—¶é—´
import time

start_time = time.time()
result = await chat_manager.chat("æµ‹è¯•é—®é¢˜")
end_time = time.time()

print(f"å“åº”æ—¶é—´: {end_time - start_time:.2f}ç§’")
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **ä¾èµ–å†²çª**
   ```bash
   # åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
   python -m venv langchain_env
   source langchain_env/bin/activate  # Linux/Mac
   # æˆ–
   langchain_env\Scripts\activate  # Windows
   ```

2. **å†…å­˜ä¸è¶³**
   ```python
   # å‡å°‘chunk_size
   text_splitter = RecursiveCharacterTextSplitter(
       chunk_size=500,  # å‡å°‘chunkå¤§å°
       chunk_overlap=100
   )
   ```

3. **APIé™åˆ¶**
   ```python
   # æ·»åŠ é‡è¯•æœºåˆ¶
   from langchain.llms import Groq
   
   llm = Groq(
       groq_api_key=api_key,
       max_retries=3,
       retry_delay=1.0
   )
   ```

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### å¯ç”¨æ—¥å¿—

```python
import logging

# è®¾ç½®LangChainæ—¥å¿—çº§åˆ«
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("langchain")
```

### æ€§èƒ½ç›‘æ§

```python
# ç›‘æ§é“¾æ‰§è¡Œæ—¶é—´
from langchain.callbacks import BaseCallbackHandler

class PerformanceCallback(BaseCallbackHandler):
    def on_chain_start(self, serialized, inputs, **kwargs):
        self.start_time = time.time()
    
    def on_chain_end(self, outputs, **kwargs):
        execution_time = time.time() - self.start_time
        print(f"é“¾æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. é“¾å¼è®¾è®¡

```python
# Useç»„åˆé“¾
from langchain.chains import LLMChain, SimpleSequentialChain

# åˆ›å»ºå­é“¾
chain1 = LLMChain(llm=llm, prompt=prompt1)
chain2 = LLMChain(llm=llm, prompt=prompt2)

# ç»„åˆé“¾
overall_chain = SimpleSequentialChain(chains=[chain1, chain2])
```

### 2. ErrorProcessing

```python
# æ·»åŠ ErrorProcessing
try:
    result = await chat_manager.chat(query)
    if not result["success"]:
        # ProcessingError
        handle_error(result["error"])
except Exception as e:
    # è®°å½•Error
    logger.error(f"èŠå¤©ProcessingFailed: {e}")
```

### 3. èµ„æºManagement

```python
# æ¸…ç†èµ„æº
def cleanup():
    langchain_config.clear_memory()
    # æ¸…ç†ä¸´æ—¶File
    # å…³é—­è¿æ¥
```

## ğŸš€ ä¸‹ä¸€æ­¥

1. **æ‰©å±•åŠŸèƒ½**ï¼šæ·»åŠ æ›´å¤šLangChainå·¥å…·å’Œé“¾
2. **ä¼˜åŒ–æ€§èƒ½**ï¼šæ ¹æ®Useæƒ…å†µè°ƒæ•´Configuration
3. **ç›‘æ§éƒ¨ç½²**ï¼šæ·»åŠ ç”Ÿäº§ç¯å¢ƒç›‘æ§
4. **æŒç»­æ”¹è¿›**ï¼šæ ¹æ®ç”¨æˆ·åé¦ˆä¼˜åŒ–System

## ğŸ“ æ”¯æŒ

å¦‚æœæ‚¨åœ¨è¿ç§»è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æµ‹è¯•æ—¥å¿—
2. æ£€æŸ¥ConfigurationFile
3. è¿è¡Œè¯Šæ–­Script
4. å‚è€ƒLangChainæ–‡æ¡£

---

ğŸ‰ æ­å–œï¼æ‚¨å·²Successè¿ç§»åˆ°LangChainæ¶æ„ï¼Œäº«å—æ›´å¼ºå¤§çš„AIQé—®ç­”Aä½“éªŒï¼
