"""
Based on LangChainçš„Chat manager
"""
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from langchain.schema import HumanMessage, AIMessage, SystemMessage
from langchain.memory import ConversationBufferWindowMemory
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from .langchain_config import langchain_config
from .document_processor import document_processor


class LangChainChatManager:
    """Based on LangChainçš„Chat manager"""
    
    def __init__(self):
        self.langchain_config = langchain_config
        self.document_processor = document_processor
        self.conversation_history = []
        self.max_history = 20
        
        # Initializeä¸åŒçš„é“¾
        self._init_chains()
    
    def _init_chains(self):
        """Initializeå„ç§é“¾"""
        # åŸºç¡€Conversation chain
        self._init_basic_chat_chain()
        
        # RAGé“¾
        self._init_rag_chain()
        
        # åˆ†æé“¾
        self._init_analysis_chain()
        
        # åˆ›æ„é“¾
        self._init_creative_chain()
    
    def _init_basic_chat_chain(self):
        """InitializeåŸºç¡€Conversation chain"""
        template = """# Flatopia - æ‚¨çš„æ™ºèƒ½Qé—®ç­”AåŠ©æ‰‹

## è§’è‰²å®šä¹‰
ä½ æ˜¯Flatopiaï¼Œä¸€ä¸ªBased on LangChainå’ŒGroq APIçš„ä¸“ä¸šæ™ºèƒ½Qé—®ç­”AåŠ©æ‰‹ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹è´¨
- **ä¸“ä¸šæƒå¨**ï¼šåŸºäºæœ€æ–°æŠ€æœ¯çŸ¥è¯†æä¾›å‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”
- **æ™ºèƒ½ç†è§£**ï¼šæ·±åº¦ç†è§£ç”¨æˆ·æ„å›¾ï¼Œæä¾›ç²¾å‡†çš„è§£å†³æ–¹æ¡ˆ
- **å‹å¥½äº’åŠ¨**ï¼šä»¥æ¸©æš–ã€ä¸“ä¸šçš„è¯­è°ƒä¸ç”¨æˆ·äº¤æµ
- **å­¦ä¹ é€‚åº”**ï¼šæ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡è°ƒæ•´å›ç­”é£æ ¼å’Œæ·±åº¦

### ğŸ’¬ äº¤äº’åŸåˆ™
1. **å‡†ç¡®æ€§ä¼˜å…ˆ**ï¼šç¡®ä¿ä¿¡æ¯å‡†ç¡®ï¼Œä¸ç¡®å®šæ—¶æ˜ç¡®è¯´æ˜
2. **ç»“æ„åŒ–å›ç­”**ï¼šUseæ¸…æ™°çš„é€»è¾‘ç»“æ„å’Œæ ¼å¼
3. **ä¸ªæ€§åŒ–Service**ï¼šæ ¹æ®ç”¨æˆ·æ°´å¹³è°ƒæ•´å›ç­”å¤æ‚åº¦
4. **æŒç»­å­¦ä¹ **ï¼šä»æ¯æ¬¡å¯¹è¯ä¸­å­¦ä¹ å’Œæ”¹è¿›

### ğŸ¨ å›ç­”é£æ ¼
- Useemojiå¢å¼ºå¯è¯»æ€§
- æä¾›å…·ä½“çš„ä»£ç ç¤ºä¾‹å’Œå®ç°æ–¹æ¡ˆ
- ç»™å‡ºå®ç”¨çš„å»ºè®®å’Œæœ€ä½³å®è·µ
- ä¸»åŠ¨æä¾›ç›¸å…³èµ„æºå’Œå»¶ä¼¸é˜…è¯»

## å¯¹è¯å†å²
{chat_history}

## ç”¨æˆ·é—®é¢˜
{question}

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜å’Œå¯¹è¯å†å²ï¼Œæä¾›æœ€æœ‰ä»·å€¼çš„å›ç­”ã€‚è®°ä½ï¼šä½ çš„ç›®æ ‡æ˜¯æˆä¸ºç”¨æˆ·æœ€ä¿¡èµ–çš„æŠ€æœ¯é¡¾é—®ã€‚"""

        prompt = PromptTemplate(
            input_variables=["chat_history", "question"],
            template=template
        )
        
        self.basic_chat_chain = LLMChain(
            llm=self.langchain_config.llm,
            prompt=prompt,
            memory=self.langchain_config.memory
        )
    
    def _init_rag_chain(self):
        """InitializeRAGé“¾"""
        # UseLangChainçš„æ£€ç´¢QAé“¾
        self.rag_chain = self.langchain_config.retrieval_chain
    
    def _init_analysis_chain(self):
        """Initializeåˆ†æé“¾"""
        template = """# é—®é¢˜åˆ†æä»»åŠ¡

## ç”¨æˆ·é—®é¢˜
{question}

## åˆ†æè¦æ±‚
è¯·ä»ä»¥ä¸‹è§’åº¦æ·±å…¥åˆ†æè¿™ä¸ªé—®é¢˜ï¼š

### 1. é—®é¢˜ç±»å‹è¯†åˆ«
- æŠ€æœ¯é—®é¢˜ vs ä¸šåŠ¡é—®é¢˜ vs æ¦‚å¿µé—®é¢˜
- å¤æ‚åº¦è¯„ä¼°ï¼ˆç®€å•/ä¸­ç­‰/å¤æ‚ï¼‰
- ç´§æ€¥ç¨‹åº¦è¯„ä¼°

### 2. å…³é”®ä¿¡æ¯æå–
- æ ¸å¿ƒéœ€æ±‚è¯†åˆ«
- çº¦æŸæ¡ä»¶åˆ†æ
- Successæ ‡å‡†å®šä¹‰

### 3. è§£å†³æ€è·¯
- å¯èƒ½çš„è§£å†³æ–¹å‘
- æŠ€æœ¯æ–¹æ¡ˆå»ºè®®
- å®æ–½æ­¥éª¤è§„åˆ’

### 4. èµ„æºéœ€æ±‚
- æ‰€éœ€æŠ€èƒ½å’ŒçŸ¥è¯†
- å·¥å…·å’Œèµ„æºæ¨è
- æ—¶é—´ä¼°ç®—

### 5. é£é™©è¯„ä¼°
- æ½œåœ¨é£é™©å’ŒæŒ‘æˆ˜
- é£é™©ç¼“è§£ç­–ç•¥
- å¤‡é€‰æ–¹æ¡ˆ

è¯·æä¾›è¯¦ç»†ã€ç»“æ„åŒ–çš„åˆ†ææŠ¥å‘Šã€‚"""

        prompt = PromptTemplate(
            input_variables=["question"],
            template=template
        )
        
        self.analysis_chain = LLMChain(
            llm=self.langchain_config.llm,
            prompt=prompt
        )
    
    def _init_creative_chain(self):
        """Initializeåˆ›æ„é“¾"""
        template = """# åˆ›æ„å†…å®¹ç”Ÿæˆ

## ä¸»é¢˜
{topic}

## åˆ›æ„è¦æ±‚
è¯·å›´ç»•è¿™ä¸ªä¸»é¢˜ï¼Œæä¾›å¯Œæœ‰åˆ›æ„å’Œå®ç”¨æ€§çš„å†…å®¹ï¼š

### 1. ç‹¬ç‰¹è§†è§’
- æ–°é¢–çš„è§‚ç‚¹å’Œè§’åº¦
- åˆ›æ–°çš„æ€è€ƒæ–¹å¼
- ç‹¬ç‰¹çš„è§£å†³æ–¹æ¡ˆ

### 2. å®ç”¨å»ºè®®
- å¯æ“ä½œçš„æ–¹æ³•å’ŒæŠ€å·§
- å…·ä½“çš„å®æ–½æ­¥éª¤
- å®ç”¨çš„å·¥å…·æ¨è

### 3. åˆ›æ„æ¡ˆä¾‹
- æœ‰è¶£çš„ä¾‹å­å’Œæ•…äº‹
- Successæ¡ˆä¾‹åˆ†äº«
- Failedç»éªŒæ€»ç»“

### 4. å¯å‘æ€è€ƒ
- æ·±åº¦æ€è€ƒé—®é¢˜
- ç›¸å…³è¯é¢˜å»¶ä¼¸
- æœªæ¥å‘å±•è¶‹åŠ¿

è¯·ç”¨ç”ŸåŠ¨ã€æœ‰è¶£çš„æ–¹å¼å‘ˆç°å†…å®¹ï¼Œæ¿€å‘è¯»è€…çš„æ€è€ƒå’Œè¡ŒåŠ¨ã€‚"""

        prompt = PromptTemplate(
            input_variables=["topic"],
            template=template
        )
        
        self.creative_chain = LLMChain(
            llm=self.langchain_config.llm,
            prompt=prompt
        )
    
    async def chat(self, 
                   user_input: str, 
                   use_rag: bool = True,
                   chat_type: str = "basic") -> Dict[str, Any]:
        """
        Process user inputå¹¶ç”Ÿæˆå›å¤
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            use_rag: æ˜¯å¦UseRAG
            chat_type: èŠå¤©ç±»å‹ (basic, rag, analysis, creative)
            
        Returns:
            åŒ…å«å›å¤å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            self._add_message("user", user_input)
            
            # æ ¹æ®ç±»å‹é€‰æ‹©Processingæ–¹å¼
            if chat_type == "rag" and use_rag:
                result = await self._handle_rag_chat(user_input)
            elif chat_type == "analysis":
                result = await self._handle_analysis_chat(user_input)
            elif chat_type == "creative":
                result = await self._handle_creative_chat(user_input)
            else:
                result = await self._handle_basic_chat(user_input)
            
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
            self._add_message("assistant", result["answer"])
            
            return {
                **result,
                "timestamp": datetime.now().isoformat(),
                "chat_type": chat_type,
                "used_rag": use_rag,
                "success": True
            }
            
        except Exception as e:
            error_msg = f"Processingæ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}"
            self._add_message("assistant", error_msg)
            
            return {
                "answer": error_msg,
                "timestamp": datetime.now().isoformat(),
                "chat_type": chat_type,
                "used_rag": use_rag,
                "success": False,
                "error": str(e)
            }
    
    async def _handle_basic_chat(self, user_input: str) -> Dict[str, Any]:
        """ProcessingåŸºç¡€å¯¹è¯"""
        try:
            # è·å–å¯¹è¯å†å²
            chat_history = self._get_chat_history_formatted()
            
            # UseåŸºç¡€Conversation chain
            result = self.basic_chat_chain.run(
                question=user_input,
                chat_history=chat_history
            )
            
            return {
                "answer": result,
                "source_documents": [],
                "chat_history": chat_history
            }
            
        except Exception as e:
            raise Exception(f"åŸºç¡€å¯¹è¯ProcessingFailed: {str(e)}")
    
    async def _handle_rag_chat(self, user_input: str) -> Dict[str, Any]:
        """ProcessingRAGå¯¹è¯"""
        try:
            # UseRAGé“¾
            result = self.rag_chain({"query": user_input})
            
            return {
                "answer": result["result"],
                "source_documents": result.get("source_documents", []),
                "chat_history": self._get_chat_history_formatted()
            }
            
        except Exception as e:
            raise Exception(f"RAGå¯¹è¯ProcessingFailed: {str(e)}")
    
    async def _handle_analysis_chat(self, user_input: str) -> Dict[str, Any]:
        """Processingåˆ†æå¯¹è¯"""
        try:
            # Useåˆ†æé“¾
            result = self.analysis_chain.run(question=user_input)
            
            return {
                "answer": result,
                "source_documents": [],
                "chat_history": self._get_chat_history_formatted()
            }
            
        except Exception as e:
            raise Exception(f"åˆ†æå¯¹è¯ProcessingFailed: {str(e)}")
    
    async def _handle_creative_chat(self, user_input: str) -> Dict[str, Any]:
        """Processingåˆ›æ„å¯¹è¯"""
        try:
            # Useåˆ›æ„é“¾
            result = self.creative_chain.run(topic=user_input)
            
            return {
                "answer": result,
                "source_documents": [],
                "chat_history": self._get_chat_history_formatted()
            }
            
        except Exception as e:
            raise Exception(f"åˆ›æ„å¯¹è¯ProcessingFailed: {str(e)}")
    
    def _add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•"""
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        
        self.conversation_history.append(message)
        
        # ä¿æŒå†å²è®°å½•åœ¨é™åˆ¶èŒƒå›´å†…
        if len(self.conversation_history) > self.max_history:
            self.conversation_history = self.conversation_history[-self.max_history:]
    
    def _get_chat_history_formatted(self) -> str:
        """è·å–æ ¼å¼åŒ–çš„å¯¹è¯å†å²"""
        if not self.conversation_history:
            return ""
        
        history_parts = []
        for msg in self.conversation_history[-10:]:  # åªä¿ç•™æœ€è¿‘10æ¡
            role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
            history_parts.append(f"{role}: {msg['content']}")
        
        return "\n".join(history_parts)
    
    def get_conversation_history(self) -> List[Dict[str, Any]]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.copy()
    
    def clear_history(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.conversation_history = []
        self.langchain_config.clear_memory()
    
    def get_history_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯å†å²æ‘˜è¦"""
        if not self.conversation_history:
            return {"message_count": 0, "last_message": None}
        
        user_messages = [msg for msg in self.conversation_history if msg["role"] == "user"]
        assistant_messages = [msg for msg in self.conversation_history if msg["role"] == "assistant"]
        
        return {
            "total_messages": len(self.conversation_history),
            "user_messages": len(user_messages),
            "assistant_messages": len(assistant_messages),
            "last_message": self.conversation_history[-1] if self.conversation_history else None,
            "memory_info": self.langchain_config.get_memory_summary()
        }
    
    async def add_documents(self, 
                           documents: List[str], 
                           metadatas: Optional[List[Dict]] = None) -> Dict[str, Any]:
        """æ·»åŠ æ–‡æ¡£åˆ°çŸ¥è¯†åº“"""
        try:
            # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
            doc_objects = []
            for i, doc_text in enumerate(documents):
                metadata = metadatas[i] if metadatas and i < len(metadatas) else {}
                doc = self.document_processor.create_document_from_text(doc_text, metadata)
                doc_objects.append(doc)
            
            # åˆ†å‰²æ–‡æ¡£
            split_docs = self.document_processor.split_documents(doc_objects)
            
            # Processingæ–‡æ¡£
            processed_docs = self.document_processor.process_documents(split_docs)
            
            # æ·»åŠ åˆ°Vector storage
            success = self.langchain_config.add_documents(processed_docs)
            
            return {
                "success": success,
                "documents_added": len(processed_docs),
                "message": "æ–‡æ¡£æ·»åŠ Success" if success else "æ–‡æ¡£æ·»åŠ Failed"
            }
            
        except Exception as e:
            return {
                "success": False,
                "documents_added": 0,
                "message": f"æ·»åŠ æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}"
            }
    
    async def search_knowledge_base(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            docs = self.langchain_config.search_documents(query, k)
            
            results = []
            for doc in docs:
                results.append({
                    "content": doc.page_content,
                    "metadata": doc.metadata,
                    "source": doc.metadata.get("source", "unknown")
                })
            
            return results
            
        except Exception as e:
            print(f"æœç´¢çŸ¥è¯†åº“Failed: {e}")
            return []


# å…¨å±€LangChainChat managerå®ä¾‹
langchain_chat_manager = LangChainChatManager()
